{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "# Own utility methods:\n",
    "from mandelbrot import *\n",
    "from sampling_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1\n",
    "We create an image of the mandelbrot set by applying the mandelbrot iteration 1000 times to a grid of complex numbers and plotting the number of iterations until divergence for each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_mandelbrot(num_div_steps, cmap='viridis', save_plot_as = 'mandelbrot_visualisation'):\n",
    "    plt.imshow(num_div_steps, cmap=cmap)\n",
    "    plt.xlabel('Real Part')\n",
    "    plt.ylabel('Imaginary Part')\n",
    "    plt.colorbar(label='Divergence Steps')\n",
    "    plt.title('Mandelbrot Set Divergence Visualization')\n",
    "\n",
    "    full_path = os.path.join('plots', save_plot_as)\n",
    "    plt.savefig(full_path, dpi=600)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "resolution = 1000\n",
    "C = generate_complex_grid(resolution)\n",
    "num_div_steps, _ = compute_mandelbrot_torch(C, max_steps=500, bound=10)\n",
    "plot_mandelbrot(num_div_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also zoom into the Mandelbrot set revealing the  intricate, self-similar patterns, enhancing visual understanding of its fractal nature.\n",
    "\n",
    "The names of the parts we zoom into:\n",
    "- Seahorse Valley\n",
    "- Elephants Valley\n",
    "- Spiral Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify these parameters for zooming\n",
    "zoom_center = (-0.75, 0.1)  # Seahorse Valley\n",
    "zoom_level = 0.1  # Smaller values for deeper zooms\n",
    "\n",
    "# Compute ranges for the zoomed-in area\n",
    "real_range = (zoom_center[0] - zoom_level, zoom_center[0] + zoom_level)\n",
    "imag_range = (zoom_center[1] - zoom_level, zoom_center[1] + zoom_level)\n",
    "\n",
    "# Generate the grid with the new zoomed-in ranges\n",
    "resolution = 1000\n",
    "C = generate_complex_grid(resolution, real_range=real_range, imag_range=imag_range)\n",
    "\n",
    "# Compute the Mandelbrot set with a high number of steps for detailed structure\n",
    "num_div_steps, area_at_step = compute_mandelbrot(C, max_steps=1000, bound=10)\n",
    "\n",
    "# Plot the result\n",
    "plot_mandelbrot(num_div_steps, cmap='viridis', save_plot_as= 'visualisation_seahorse')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify these parameters for zooming\n",
    "zoom_center = (0.3, -0.05) # Elephants Valley\n",
    "zoom_level = 0.05  # Smaller values for deeper zooms \n",
    "\n",
    "# Compute ranges for the zoomed-in area\n",
    "real_range = (zoom_center[0] - zoom_level, zoom_center[0] + zoom_level)\n",
    "imag_range = (zoom_center[1] - zoom_level, zoom_center[1] + zoom_level)\n",
    "\n",
    "# Generate the grid with the new zoomed-in ranges\n",
    "resolution = 1000\n",
    "C = generate_complex_grid(resolution, real_range=real_range, imag_range=imag_range)\n",
    "\n",
    "# Compute the Mandelbrot set with a high number of steps for detailed structure\n",
    "num_div_steps, area_at_step = compute_mandelbrot(C, max_steps=1000, bound=10)\n",
    "\n",
    "# Plot the result\n",
    "plot_mandelbrot(num_div_steps, cmap='viridis', save_plot_as= 'visualisation_elephant') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify these parameters for zooming\n",
    "zoom_center = (-0.7, 0.3) # Spiral Region\n",
    "zoom_level = 0.05  # Smaller values for deeper zooms \n",
    "\n",
    "# Compute ranges for the zoomed-in area\n",
    "real_range = (zoom_center[0] - zoom_level, zoom_center[0] + zoom_level)\n",
    "imag_range = (zoom_center[1] - zoom_level, zoom_center[1] + zoom_level)\n",
    "\n",
    "# Generate the grid with the new zoomed-in ranges\n",
    "resolution = 2000\n",
    "C = generate_complex_grid(resolution, real_range=real_range, imag_range=imag_range)\n",
    "\n",
    "# Compute the Mandelbrot set with a high number of steps for detailed structure\n",
    "num_div_steps, area_at_step = compute_mandelbrot(C, max_steps=1000, bound=10)\n",
    "\n",
    "# Plot the result\n",
    "plot_mandelbrot(num_div_steps, cmap='viridis', save_plot_as= 'visualisation_spiral') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2\n",
    "Convergence of the Area estimate with the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_mandelbrot_area_difference(sample_sizes, iteration_count, skip_iterations = 0, save_plot_as = 'mandelbrot-convergence-iterations.png'):\n",
    "    area_estimates = np.zeros((len(sample_sizes), iteration_count))\n",
    "\n",
    "    for i, num_samples in enumerate(sample_sizes):\n",
    "        C = uniform_random_sampling(num_samples, (-2,2),(-2,2))\n",
    "        _, area_est = compute_mandelbrot_torch(C, iteration_count, area_factor=16 )\n",
    "        area_estimates[i,:] = area_est\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, samples in enumerate(sample_sizes):\n",
    "        plt.plot(np.arange(iteration_count)[skip_iterations:]+1, np.abs(area_estimates[i,-1] - area_estimates[i, skip_iterations:]), label=f's = {samples}')\n",
    "\n",
    "    plt.xlabel('Iteration j')\n",
    "    plt.ylabel(r'$A_{j, s} - A_{i, s}$')\n",
    "    plt.title('Convergence of Estimated Area depending on Iteration Count')\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    full_path = os.path.join('plots', save_plot_as)\n",
    "    plt.savefig(full_path, dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "    return area_estimates\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parameters used for the plot in the report (runs for over 1 hour):\n",
    "# sample_sizes = [1000, 10000, 100000, 1000000]\n",
    "# iteration_count = 5000000\n",
    "\n",
    "# example with lower run time\n",
    "sample_sizes = [1000, 10000, 100000]\n",
    "iteration_count = 10000\n",
    "\n",
    "plot_mandelbrot_area_difference(sample_sizes, iteration_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoeffding's inequality:\n",
    "\n",
    "for a series of independent random variables $X_i \\in [0,1]$  writing $S_n = \\frac1n\\sum_{i=1}^n X_i$\n",
    "\\begin{align}\n",
    "     P(|S_n - E[S_n]| \\geq \\varepsilon) \\leq 2 exp \\left(-2\\varepsilon^2 n\\right) &\\leq \\delta\\\\\n",
    "     {2\\varepsilon^2n} &\\leq -log(\\delta / 2) \\\\\n",
    "    \\varepsilon &\\leq \\sqrt{-\\frac 1{2n} log(\\delta / 2)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convergence with number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mandelbrot_area_difference_sample_count(sample_sizes, iteration_count, sampling_methods, method_titles, save_plot_as = 'images/mandelbrot-convergence-samples.png'):\n",
    "    area_estimates = np.zeros((len(sampling_methods), len(sample_sizes)))\n",
    "\n",
    "    for m, method in enumerate(sampling_methods):\n",
    "        for i, num_samples in enumerate(sample_sizes):\n",
    "            C = method(num_samples, (-2,2),(-2,2))\n",
    "            _, area_est = compute_mandelbrot_torch(C, iteration_count, area_factor=16 )\n",
    "            area_estimates[m, i] = area_est[-1]\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    markers=['o', 'v', '^','s', 'p' ]   \n",
    "\n",
    "    for m, method in enumerate(sampling_methods):\n",
    "        plt.plot(sample_sizes[:-1], np.abs(area_estimates[m, :-1] - area_estimates[m, -1]), label=method_titles[m], marker = markers[m] )\n",
    "\n",
    "    plt.xlabel('Sample Size s')\n",
    "    plt.ylabel(r'$A_{i, s} - A_{i, s_{max}}$')\n",
    "    plt.title('Convergence of Estimated Area depending on Sample Size')\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    full_path = os.path.join('plots', save_plot_as)\n",
    "    plt.savefig(full_path, dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "    return area_estimates\n",
    "\n",
    "\n",
    "\n",
    "sample_sizes = np.logspace(3, 7, 20, base=10).astype(np.int64)\n",
    "iteration_count = 10000\n",
    "sampling_methods = [ uniform_random_sampling, latin_hypercube_sampling,  orthogonal_sampling]\n",
    "method_titles = [ 'uniform random', 'latin hypercube', 'orthogonal']\n",
    "area_estimates = plot_mandelbrot_area_difference_sample_count(sample_sizes, iteration_count, sampling_methods, method_titles)\n",
    "print(area_estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3\n",
    "In this part we look at different sampling methods to estimate the size of the Mandelbrot set to compare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Pure Random Sampling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sampling_method(C, title, max_steps=1000, area_factor=9, save_plot_as = 'sampling_method'):\n",
    "    \"\"\"\n",
    "    Computes and plots Mandelbrot set divergence steps for a given complex array using a specified sampling method.\n",
    "\n",
    "    Parameters:\n",
    "    - C: 1D array of complex numbers representing the samples.\n",
    "    - title: Title for the plot.\n",
    "    - max_steps: Maximum number of iterations for Mandelbrot computation.\n",
    "    - area_factor: Area factor for the computation.\n",
    "    \"\"\"\n",
    "    num_div_steps, area_at_step = compute_mandelbrot(C, max_steps=max_steps, area_factor=area_factor)\n",
    "\n",
    "    rval, ival = C.real, C.imag\n",
    "    plt.scatter(rval, ival, s=0.1, alpha=0.1, c=num_div_steps)\n",
    "    plt.xlabel('Real Part')\n",
    "    plt.ylabel('Imaginary Part')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(label='Divergence Steps')\n",
    "\n",
    "    full_path = os.path.join('plots', save_plot_as)\n",
    "    plt.savefig(full_path, dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "def pure_random_sampling(num_samples, real_range=(-2, 1), imag_range=(-1.5, 1.5), seed=42):\n",
    "    \"\"\"\n",
    "    Performs pure random sampling for the Mandelbrot set.\n",
    "\n",
    "    Parameters:\n",
    "    - num_samples: Number of samples.\n",
    "    - real_range: Tuple specifying the range for the real axis.\n",
    "    - imag_range: Tuple specifying the range for the imaginary axis.\n",
    "    - seed: Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - C: 1D array of complex numbers representing the samples.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    rval = np.random.uniform(real_range[0], real_range[1], num_samples)\n",
    "    ival = np.random.uniform(imag_range[0], imag_range[1], num_samples)\n",
    "    return rval + 1.j * ival\n",
    "\n",
    "# Example Usage\n",
    "C = pure_random_sampling(num_samples=100000)\n",
    "plot_sampling_method(C, \"Mandelbrot Set Divergence Steps (Pure Random Sampling)\", save_plot_as = 'pure_random_sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Orthogonal Sampling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthogonal_sampling(num_samples, real_range=(-2, 1), imag_range=(-1.5, 1.5), seed=42):\n",
    "    \"\"\"\n",
    "    Performs orthogonal sampling for the Mandelbrot set, suited for Python while following the logic of the provided C code.\n",
    "\n",
    "    Parameters:\n",
    "    - num_samples: Total number of samples to generate (must be a perfect square).\n",
    "    - real_range: Tuple specifying the range for the real axis.\n",
    "    - imag_range: Tuple specifying the range for the imaginary axis.\n",
    "    - seed: Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - C: 1D array of complex numbers representing the samples.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    major = int(np.round(np.sqrt(num_samples)))\n",
    "    num_samples = major * major\n",
    "    print(f\"Adjusted num_samples to {num_samples} to ensure it is a perfect square close to the original value.\")\n",
    "\n",
    "    x_indices = np.arange(major)\n",
    "    y_indices = np.arange(major)\n",
    "\n",
    "    samples = []\n",
    "    for i in range(major):\n",
    "        np.random.shuffle(x_indices)\n",
    "        np.random.shuffle(y_indices)\n",
    "\n",
    "        for j in range(major):\n",
    "            rand_real = np.random.uniform(0, 1)\n",
    "            rand_imag = np.random.uniform(0, 1)\n",
    "\n",
    "            x = real_range[0] + (real_range[1] - real_range[0]) * ((i + rand_real) / major)\n",
    "            y = imag_range[0] + (imag_range[1] - imag_range[0]) * ((j + rand_imag) / major)\n",
    "\n",
    "            samples.append(complex(x, y))\n",
    "\n",
    "    return np.array(samples)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "C = orthogonal_sampling(num_samples=100000)\n",
    "plot_sampling_method(C, \"Mandelbrot Set Divergence Steps (Orthogonal Sampling)\", save_plot_as='orthogonal_sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Latin HyperCube Sampling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latin_hypercube_sampling(num_samples, real_range=(-2, 1), imag_range=(-1.5, 1.5), seed=42):\n",
    "    \"\"\"\n",
    "    Performs Latin Hypercube sampling for the Mandelbrot set.\n",
    "\n",
    "    Parameters:\n",
    "    - num_samples: Number of samples.\n",
    "    - real_range: Tuple specifying the range for the real axis.\n",
    "    - imag_range: Tuple specifying the range for the imaginary axis.\n",
    "    - seed: Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - C: 1D array of complex numbers representing the samples.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    sampler = LatinHypercube(d=2)\n",
    "    lhs_samples = sampler.random(n=num_samples)\n",
    "\n",
    "    scaled_samples = scale(lhs_samples, [real_range[0], imag_range[0]], [real_range[1], imag_range[1]])\n",
    "    rval, ival = scaled_samples[:, 0], scaled_samples[:, 1]\n",
    "    return rval + 1.j * ival\n",
    "\n",
    "# Example Usage\n",
    "C = latin_hypercube_sampling(num_samples=100000)\n",
    "plot_sampling_method(C, \"Mandelbrot Set Divergence Steps (Latin Hypercube Sampling)\", save_plot_as = 'latin_hypercube_sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_mandelbrot(c, max_iter):\n",
    "    \"\"\"\n",
    "    Determines if a complex number is in the Mandelbrot set.\n",
    "\n",
    "    Parameters:\n",
    "    - c: Complex number.\n",
    "    - max_iter: Maximum number of iterations to check.\n",
    "\n",
    "    Returns:\n",
    "    - Boolean indicating whether the point is in the Mandelbrot set.\n",
    "    \"\"\"\n",
    "    z = 0\n",
    "    for n in range(max_iter):\n",
    "        z = z*z + c\n",
    "        if abs(z) > 2:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def estimate_area_mandelbrot(num_samples, max_iter, real_range=(-3, 1), imag_range=(-2, 2)):\n",
    "    \"\"\"\n",
    "    Estimates the area of the Mandelbrot set using Monte Carlo sampling.\n",
    "\n",
    "    Parameters:\n",
    "    - num_samples: Number of random samples.\n",
    "    - max_iter: Maximum number of iterations for Mandelbrot check.\n",
    "    - real_range: Range of real values (tuple).\n",
    "    - imag_range: Range of imaginary values (tuple).\n",
    "\n",
    "    Returns:\n",
    "    - Estimated area of the Mandelbrot set.\n",
    "    \"\"\"\n",
    "    real = np.random.uniform(real_range[0], real_range[1], num_samples)\n",
    "    imag = np.random.uniform(imag_range[0], imag_range[1], num_samples)\n",
    "    complex_samples = real + 1j * imag\n",
    "\n",
    "    in_set = np.array([is_in_mandelbrot(c, max_iter) for c in complex_samples])\n",
    "\n",
    "    rect_area = (real_range[1] - real_range[0]) * (imag_range[1] - imag_range[0])\n",
    "    area_estimate = np.mean(in_set) * rect_area\n",
    "    return area_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using Adaptive Sampling, a method used to iteratively improve the estimation of an area by focusing on regions with higher variance.\n",
    "# The idea behind adaptive sampling is to refine the sampling process over multiple iterations,\n",
    "# allowing the method to adapt and focus more on areas that are likely to contribute more to the accuracy of the final result.\n",
    "\n",
    "true_area = 1.5063\n",
    "\n",
    "# Function for Importance Sampling\n",
    "def importance_sampling(num_samples, max_iter, real_range=(-2, 1), imag_range=(-1.5, 1.5), seed=None):\n",
    "    if seed is None:\n",
    "        seed = random.randint(0, 10000)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    mean_real = 0\n",
    "    mean_imag = 0\n",
    "    std_dev = 0.8\n",
    "\n",
    "    real_samples = np.random.normal(mean_real, std_dev, num_samples)\n",
    "    imag_samples = np.random.normal(mean_imag, std_dev, num_samples)\n",
    "\n",
    "    real_samples = np.clip(real_samples, real_range[0], real_range[1])\n",
    "    imag_samples = np.clip(imag_samples, imag_range[0], imag_range[1])\n",
    "\n",
    "    complex_samples = real_samples + 1j * imag_samples\n",
    "\n",
    "    proposal_density = (1 / (2 * np.pi * std_dev**2)) * np.exp(-(real_samples**2 + imag_samples**2) / (2 * std_dev**2))\n",
    "\n",
    "    in_set = np.array([is_in_mandelbrot(c, max_iter) for c in complex_samples])\n",
    "\n",
    "    target_density = 1 / ((real_range[1] - real_range[0]) * (imag_range[1] - imag_range[0]))\n",
    "\n",
    "    weights = target_density / proposal_density\n",
    "\n",
    "    rect_area = (real_range[1] - real_range[0]) * (imag_range[1] - imag_range[0])\n",
    "    weighted_area_estimate = np.mean(in_set * weights) * rect_area\n",
    "\n",
    "    return weighted_area_estimate\n",
    "\n",
    "# Function for Sobol Sampling (Quasi-Monte Carlo)\n",
    "def sobol_sampling(num_samples, real_range=(-2, 1), imag_range=(-1.5, 1.5), seed=None):\n",
    "    if seed is None:\n",
    "        seed = random.randint(0, 10000)\n",
    "    np.random.seed(seed)\n",
    "    sampler = Sobol(d=2, scramble=True)\n",
    "    sobol_samples = sampler.random(n=num_samples)\n",
    "\n",
    "    scaled_samples = scale(sobol_samples, [real_range[0], imag_range[0]], [real_range[1], imag_range[1]])\n",
    "\n",
    "    rval, ival = scaled_samples[:, 0], scaled_samples[:, 1]\n",
    "    return rval + 1.j * ival\n",
    "\n",
    "# Function for Adaptive Sampling\n",
    "def adaptive_sampling(num_samples, max_iter, real_range=(-2, 1), imag_range=(-1.5, 1.5), seed=None, iterations=10):\n",
    "    if seed is None:\n",
    "        seed = random.randint(0, 10000)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    rval = np.random.uniform(real_range[0], real_range[1], num_samples)\n",
    "    ival = np.random.uniform(imag_range[0], imag_range[1], num_samples)\n",
    "    complex_samples = rval + 1.j * ival\n",
    "\n",
    "    in_set = np.array([is_in_mandelbrot(c, max_iter) for c in complex_samples])\n",
    "    rect_area = (real_range[1] - real_range[0]) * (imag_range[1] - imag_range[0])\n",
    "    area_estimate = np.mean(in_set) * rect_area\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        variance = np.var(in_set)\n",
    "\n",
    "        num_refine_samples = int(num_samples * 0.5)  # Increase sample size\n",
    "        refine_rval = np.random.uniform(real_range[0], real_range[1], num_refine_samples)\n",
    "        refine_ival = np.random.uniform(imag_range[0], imag_range[1], num_refine_samples)\n",
    "\n",
    "        refine_samples = refine_rval + 1.j * refine_ival\n",
    "        complex_samples = np.concatenate((complex_samples, refine_samples))\n",
    "\n",
    "        in_set = np.array([is_in_mandelbrot(c, max_iter) for c in complex_samples])\n",
    "\n",
    "        area_estimate = np.mean(in_set) * rect_area\n",
    "\n",
    "    return area_estimate\n",
    "\n",
    "def run_simulations(sample_sizes, max_iter=1000):\n",
    "    errors_random = []\n",
    "    errors_importance = []\n",
    "    errors_sobol = []\n",
    "    errors_adaptive = []\n",
    "\n",
    "    for num_samples in sample_sizes:\n",
    "        seed = random.randint(0, 10000)\n",
    "\n",
    "        # Normal Monte Carlo (Random Sampling)\n",
    "        C_random = pure_random_sampling(num_samples, seed=seed)\n",
    "        area_random = estimate_area_mandelbrot(C_random, max_iter)  # Pass C_random instead of len(C_random)\n",
    "        error_random = abs(area_random - true_area)\n",
    "        errors_random.append(error_random)\n",
    "\n",
    "        # Importance Sampling\n",
    "        area_importance = importance_sampling(num_samples, max_iter, seed=seed)\n",
    "        error_importance = abs(area_importance - true_area)\n",
    "        errors_importance.append(error_importance)\n",
    "\n",
    "        # Sobol Sampling (Quasi-Monte Carlo)\n",
    "        C_sobol = sobol_sampling(num_samples, seed=seed)\n",
    "        area_sobol = estimate_area_mandelbrot(C_sobol, max_iter)  # Pass C_sobol instead of len(C_sobol)\n",
    "        error_sobol = abs(area_sobol - true_area)\n",
    "        errors_sobol.append(error_sobol)\n",
    "\n",
    "        # Adaptive Sampling\n",
    "        area_adaptive = adaptive_sampling(num_samples, max_iter, seed=seed)\n",
    "        error_adaptive = abs(area_adaptive - true_area)\n",
    "        print(error_adaptive)\n",
    "        errors_adaptive.append(error_adaptive)\n",
    "\n",
    "    return errors_random, errors_importance, errors_sobol, errors_adaptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Refactored AdaptiveSampler class\n",
    "class AdaptiveSampler:\n",
    "    def __init__(self, num_samples, max_iter, real_range=(-2, 1), imag_range=(-1.5, 1.5),\n",
    "                 seed=None, error_threshold=1e-4, max_iterations=10):\n",
    "        self.num_samples = num_samples\n",
    "        self.max_iter = max_iter\n",
    "        self.real_range = real_range\n",
    "        self.imag_range = imag_range\n",
    "        self.seed = seed if seed is not None else random.randint(0, 10000)\n",
    "        self.error_threshold = error_threshold\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        self.initial_grid_size = max(1, int(np.sqrt(self.num_samples)))\n",
    "        self.initial_samples_per_region = max(1, self.num_samples // (self.initial_grid_size ** 2))\n",
    "        self.regions = self.create_grid()\n",
    "\n",
    "    class Region:\n",
    "        def __init__(self, x_min, x_max, y_min, y_max):\n",
    "            self.x_min = x_min\n",
    "            self.x_max = x_max\n",
    "            self.y_min = y_min\n",
    "            self.y_max = y_max\n",
    "            self.samples = []\n",
    "            self.in_set_counts = []\n",
    "            self.total_samples = 0\n",
    "            self.local_area_estimate = 0\n",
    "            self.local_variance = np.inf\n",
    "\n",
    "        def sample(self, num_samples, max_iter):\n",
    "            x_samples = np.random.uniform(self.x_min, self.x_max, num_samples)\n",
    "            y_samples = np.random.uniform(self.y_min, self.y_max, num_samples)\n",
    "            complex_samples = x_samples + 1j * y_samples\n",
    "            in_set = np.array([is_in_mandelbrot(c, max_iter) for c in complex_samples])\n",
    "            self.samples.extend(complex_samples)\n",
    "            self.in_set_counts.extend(in_set)\n",
    "            self.total_samples += num_samples\n",
    "            area = (self.x_max - self.x_min) * (self.y_max - self.y_min)\n",
    "            p = np.mean(self.in_set_counts)\n",
    "            self.local_area_estimate = p * area\n",
    "            if self.total_samples > 0:\n",
    "                self.local_variance = (p * (1 - p) / self.total_samples) * area ** 2\n",
    "            else:\n",
    "                self.local_variance = np.inf\n",
    "\n",
    "        def increase_sample_count(self, num_samples, max_iter):\n",
    "            self.sample(num_samples, max_iter)\n",
    "\n",
    "    def create_grid(self):\n",
    "        x_min, x_max = self.real_range\n",
    "        y_min, y_max = self.imag_range\n",
    "        x_edges = np.linspace(x_min, x_max, self.initial_grid_size + 1)\n",
    "        y_edges = np.linspace(y_min, y_max, self.initial_grid_size + 1)\n",
    "        regions = []\n",
    "        for i in range(self.initial_grid_size):\n",
    "            for j in range(self.initial_grid_size):\n",
    "                region = self.Region(x_edges[i], x_edges[i + 1], y_edges[j], y_edges[j + 1])\n",
    "                regions.append(region)\n",
    "        return regions\n",
    "\n",
    "    def combine_region_estimates(self):\n",
    "        total_area_estimate = sum(region.local_area_estimate for region in self.regions)\n",
    "        return total_area_estimate\n",
    "\n",
    "    def estimate_overall_variance(self):\n",
    "        total_variance = sum(region.local_variance for region in self.regions)\n",
    "        return total_variance\n",
    "\n",
    "    def select_regions_with_high_variance(self, fraction=0.5):\n",
    "        variances = np.array([region.local_variance for region in self.regions])\n",
    "        threshold = np.percentile(variances, 100 * (1 - fraction))\n",
    "        regions_to_refine = [region for region in self.regions if region.local_variance >= threshold]\n",
    "        return regions_to_refine\n",
    "\n",
    "    def run(self):\n",
    "        for iteration in range(self.max_iterations):\n",
    "            # Sample in each region\n",
    "            for region in self.regions:\n",
    "                if region.total_samples == 0:\n",
    "                    samples_to_draw = self.initial_samples_per_region\n",
    "                else:\n",
    "                    samples_to_draw = max(1, self.initial_samples_per_region // (iteration + 1))\n",
    "                region.sample(samples_to_draw, self.max_iter)\n",
    "            # Combine estimates\n",
    "            area_estimate = self.combine_region_estimates()\n",
    "            # Estimate variance\n",
    "            variance_estimate = self.estimate_overall_variance()\n",
    "            # Check for convergence\n",
    "            if variance_estimate < self.error_threshold:\n",
    "                break\n",
    "            # Select regions to refine\n",
    "            regions_to_refine = self.select_regions_with_high_variance()\n",
    "            if not regions_to_refine:\n",
    "                break\n",
    "            additional_samples = max(1, self.initial_samples_per_region // (iteration + 1))\n",
    "            for region in regions_to_refine:\n",
    "                region.increase_sample_count(additional_samples, self.max_iter)\n",
    "        return area_estimate\n",
    "\n",
    "\n",
    "def run_simulations(sample_sizes, max_iter=1000):\n",
    "    errors_random = []\n",
    "    errors_adaptive = []\n",
    "    errors_orthogonal = []\n",
    "\n",
    "    for num_samples in sample_sizes:\n",
    "        seed = random.randint(0, 10000)\n",
    "\n",
    "        # Normal Monte Carlo (Random Sampling)\n",
    "        C_random = pure_random_sampling(num_samples, seed=seed)\n",
    "        area_random = estimate_area_mandelbrot(C_random, max_iter)\n",
    "        error_random = abs(area_random - true_area)\n",
    "        errors_random.append(error_random)\n",
    "\n",
    "        # Orthogonal Sampling\n",
    "        C_orthogonal = orthogonal_sampling(num_samples, real_range=(-2, 1), imag_range=(-1.5, 1.5), seed=seed)\n",
    "        area_orthogonal = estimate_area_mandelbrot(C_orthogonal, max_iter)\n",
    "        error_orthogonal = abs(area_orthogonal - true_area)\n",
    "        errors_orthogonal.append(error_orthogonal)\n",
    "\n",
    "        # Adaptive Sampling\n",
    "        adaptive_sampler = AdaptiveSampler(num_samples, max_iter, seed=seed)\n",
    "        area_adaptive = adaptive_sampler.run()\n",
    "        error_adaptive = abs(area_adaptive - true_area)\n",
    "        errors_adaptive.append(error_adaptive)\n",
    "\n",
    "    return errors_random, errors_orthogonal, errors_adaptive\n",
    "\n",
    "min_sample_size = 1000\n",
    "max_sample_size = 1000000\n",
    "sample_sizes = np.logspace(np.log10(min_sample_size), np.log10(max_sample_size), num=29).astype(int)\n",
    "\n",
    "errors_random, errors_orthogonal, errors_adaptive = run_simulations(sample_sizes)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_orthogonal = np.mean(errors_orthogonal)\n",
    "std_orthogonal = np.std(errors_orthogonal)\n",
    "mean_adaptive = np.mean(errors_adaptive)\n",
    "std_adaptive = np.std(errors_adaptive)\n",
    "\n",
    "# Statistical comparison\n",
    "t_stat, p_value = stats.ttest_ind(errors_orthogonal, errors_adaptive)\n",
    "print(f\"t-statistic: {t_stat}, p-value: {p_value}\")\n",
    "\n",
    "# Print results\n",
    "print(\"Statistical Summary:\")\n",
    "print(f\"Orthogonal Sampling: Mean = {mean_orthogonal:.4f}, Std Dev = {std_orthogonal:.4f}\")\n",
    "print(f\"Adaptive Sampling: Mean = {mean_adaptive:.4f}, Std Dev = {std_adaptive:.4f}\")\n",
    "print(\"\\nT-tests Results:\")\n",
    "print(f\"Orthogonal vs Adaptive: t-statistic = {t_stat:.4f}, p-value = {p_value:.4g}\")\n",
    "\n",
    "# Plotting results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.loglog(sample_sizes, errors_adaptive, marker='o', label=\"Adaptive Sampling\")\n",
    "plt.loglog(sample_sizes, errors_orthogonal, marker='o', label=\"Orthogonal Sampling\")\n",
    "plt.xlabel('Number of Samples')\n",
    "plt.ylabel('Error |A_est - A_true|')\n",
    "plt.title('Comparison of Convergence Rates for Monte Carlo Methods')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
